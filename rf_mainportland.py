# -*- coding: utf-8 -*-
"""rf_PO_SC-MURDERS2016_2022.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fEIs_DHn8B2xudbwQlhB4zqbXA8ZXau_
"""

import tensorflow as tf
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import warnings
import numpy as np

!cp /content/drive/MyDrive/Colab\ Notebooks/ePredictor/preprocess.py /content

import preprocess
df=preprocess.getfile()

df.index = pd.to_datetime(df['MonthYear'], format='%d/%m/%Y')
df[:24]

temp = df['SeriousCrimes']
temp.plot() #grab Homicide Offenses

def df_to_X_y(df, window_size=6):
 df_as_np = df.to_numpy()
 X =[]
 y =[]
 for i in range(len(df_as_np)-window_size):
  row = [[a] for a in df_as_np[i:i+6]]
  X.append(row)
  label = df_as_np[i+6]
  y.append(label)
 return np.array(X), np.array(y)

window_size =6
X, y = df_to_X_y(temp, window_size)

X_train, y_train = X[:60], y[:60]
X_test, y_test = X[67:79], y[78:]

X_test

X_train = X_train.reshape(60,6)

model = RandomForestClassifier(n_estimators = 10, random_state = 30)

arrSize = 10
arrList = list(range(arrSize))
count = list(range(arrSize))

lstSize = 1000
size = 25  #initilising size to 25
newsize = 0
oplist = list(range(12))
newlist = list(range(12))
for h in range(0,lstSize):
 import warnings
 warnings.filterwarnings("ignore")
 model.fit(X_train,y_train)

 import warnings
 warnings.filterwarnings("ignore")
 X_test = X_test.reshape(12,6)
 opplist= model.predict(X_test)
 for i in range(1,arrSize):
   newlist = model.predict(X_test)
   #print(newlist)
   newsize = 0
   for k in range(0,12):
    if (y_test[k] != newlist[k]):
      newsize += (abs(y_test[k]-newlist[k]))
   print (newsize)
   print (newlist)
   if (newsize < size):
    size = newsize
    oplist = newlist
    print (oplist)
print ("\n")
print (size)
print (oplist)

test_predictions = oplist
# model.predict(X_test).flatten()
test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test})
test_results

import matplotlib.pyplot as plt
plt.plot(test_results['Test Predictions'])
plt.plot(test_results['Actuals'])
plt.xlabel("Months")
plt.ylabel("State")
plt.legend(['Prediction', 'Actual'])
#dim=plt.subplot(111)
#dim.set_xlim(1, 12)
plt.title("Arima (Trinidad W.I.) Police Department")

forecast_errors = [y_test[i]-test_predictions[i] for i in range(len(y_test))]
print('Forecast Errors: %s' % forecast_errors)

y_test

test_predictions

mean_forecast_error = sum(forecast_errors)/12
print('Mean_Forecast_Error: %f' % mean_forecast_error)

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(y_test, test_predictions)
print('Accuracy: %f' % accuracy)

test_predictions

y_test

# precision tp / (tp + fp)
precision = precision_score(y_test,test_predictions, pos_label='positive', average='weighted')
print('Precision: %f' % precision)

# recall: tp / (tp + fn)
recall = recall_score(y_test, test_predictions, pos_label='positive', average='weighted')
print('Recall: %f' % recall)

# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(y_test, test_predictions, pos_label='positive', average='weighted')
print('F1 score: %f' % f1)